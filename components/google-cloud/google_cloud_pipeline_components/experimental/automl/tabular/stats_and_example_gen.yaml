name: Tabular Stats and Example Gen
inputs:
- {name: project, type: String}
- {name: location, type: String}
- {name: image_uri, type: String, default: "us-docker.pkg.dev/vertex-ai-restricted/automl-tabular/training:prod"}
- {name: dataflow_worker_image_uri, type: String, default: "us-docker.pkg.dev/vertex-ai/automl-tabular/dataflow-worker:prod"}
- {name: root_dir, type: String}
- {name: target_column_name, type: String}
- {name: weight_column_name, type: String, default: ""}
- {name: prediction_type, type: String}
- {name: optimization_objective, type: String}
- {name: optimization_objective_recall_value, type: Float, default: "-1"}
- {name: optimization_objective_precision_value, type: Float, default: "-1"}
- {name: transformations, type: String}
- {name: split_spec, type: String}
- {name: data_source, type: String}
- {name: dataflow_machine_type, type: String, default: "n1-standard-16"}
- {name: dataflow_max_num_workers, type: Integer, default: "25"}
- {name: dataflow_disk_size_gb, type: Integer, default: "40"}
- {name: encryption_spec_key_name, type: String, default: ""}
- {name: is_distill, type: Boolean, default: "false"}

outputs:
- {name: dataset_schema, type: DatasetSchema}
- {name: dataset_stats, type: AutoMLTabularDatasetStats}
- {name: train_split, type: TabularDatasetSplit}
- {name: eval_split, type: TabularDatasetSplit}
- {name: test_split, type: TabularDatasetSplit}
- {name: test_split_json, type: JsonObject}
- {name: instance_baseline, type: AutoMLTabularInstanceBaseline}
- {name: metadata, type: TabularExampleGenMetadata}
- {name: gcp_resources, type: String}

implementation:
  container:
    image: gcr.io/ml-pipeline/google-cloud-pipeline-components:0.1.7
    command: [python3, -u, -m, google_cloud_pipeline_components.experimental.remote.gcp_launcher.launcher]
    args: [
      --type, CustomJob,
      --project, {inputValue: project},
      --location, {inputValue: location},
      --gcp_resources, {outputPath: gcp_resources},
      --payload,
      concat: [
        '{"display_name": "tabular-stats-and-example-gen-{{$.pipeline_job_uuid}}-{{$.pipeline_task_uuid}}", "encryption_spec": {"kms_key_name":"',
        {inputValue: encryption_spec_key_name},
        '"}, "job_spec": {"worker_pool_specs": [{"replica_count": 1, "machine_spec": {"machine_type": "n1-standard-8"}, "container_spec": {"image_uri":"',
        {inputValue: image_uri},
        '", "args": ["stats_generator",',
        '"--train_spec={\"prediction_type\": \"',
        {inputValue: prediction_type},
        '\", \"target_column\": \"',
        {inputValue: target_column_name},
        '\", \"optimization_objective\": \"',
        {inputValue: optimization_objective},
        '\", \"weight_column_name\": \"',
        {inputValue: weight_column_name},
        '\", \"transformations\": ',
        {inputValue: transformations},
        '}", "--split_spec=',
        {inputValue: split_spec},
        '", "--data_source=',
        {inputValue: data_source},
        '", "--target_column=',
        {inputValue: target_column_name},
        '", "--request_type=COLUMN_STATS_ONLY',
        '", "--optimization_objective_recall_value=',
        {inputValue: optimization_objective_recall_value},
        '", "--optimization_objective_precision_value=',
        {inputValue: optimization_objective_precision_value},
        '", "--example_gen_gcs_output_prefix=',
        {inputValue: root_dir},
        '/{{$.pipeline_job_uuid}}/{{$.pipeline_task_uuid}}/example_gen_output", "--dataset_stats_dir=',
        {inputValue: root_dir},
        '/{{$.pipeline_job_uuid}}/{{$.pipeline_task_uuid}}/stats/", "--stats_result_path=',
        {outputUri: dataset_stats},
        '", "--dataset_schema_path=',
        {outputUri: dataset_schema},
        '", "--job_name=tabular-stats-and-example-gen-{{$.pipeline_job_uuid}}-{{$.pipeline_task_uuid}}',
        '", "--dataflow_project=',
        {inputValue: project},
        '", "--error_file_path=',
        {inputValue: root_dir},
        '/{{$.pipeline_job_uuid}}/{{$.pipeline_task_uuid}}/error.pb", "--dataflow_staging_dir=',
        {inputValue: root_dir},
        '/{{$.pipeline_job_uuid}}/{{$.pipeline_task_uuid}}/dataflow_staging", "--dataflow_tmp_dir=',
        {inputValue: root_dir},
        '/{{$.pipeline_job_uuid}}/{{$.pipeline_task_uuid}}/dataflow_tmp", "--dataflow_max_num_workers=',
        {inputValue: dataflow_max_num_workers},
        '", "--dataflow_worker_container_image=',
        {inputValue: dataflow_worker_image_uri},
        '", "--dataflow_machine_type=',
        {inputValue: dataflow_machine_type},
        '", "--dataflow_disk_size_gb=',
        {inputValue: dataflow_disk_size_gb},
        '", "--dataflow_kms_key=',
        {inputValue: encryption_spec_key_name},
        '", "--is_distill=',
        {inputValue: is_distill},
        '", "--metadata_path=',
        {outputUri: metadata},
        '", "--train_split=',
        {outputUri: train_split},
        '", "--eval_split=',
        {outputUri: eval_split},
        '", "--test_split=',
        {outputUri: test_split},
        '", "--test_split_for_batch_prediction_component=',
        {outputPath: test_split_json},
        '", "--instance_baseline_path=',
        {outputUri: instance_baseline},
        '", "--parse_json=true"]}}]}}'
      ]]
